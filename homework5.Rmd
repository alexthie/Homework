---
title: 'Bios 6301: Assignment 5'
author: "Alexander Thiemicke"
email: alexander.thiemicke@vanderbilt.edu
date: "2015-11-10"
#"'r format(Sys.time(), '%B, %d, %Y')"
output: pdf_document
---

*Due Tuesday, 10 November, 1:00 PM*

$5^{n=day}$ points taken off for each day late.

50 points total.

Submit a single knitr file (named `homework5.rmd`), along with a valid PDF output file. Inside the file, clearly indicate which parts of your responses go with which problems (you may use the original homework document as a template). Add your name as `author` to the file's metadata section. Raw R code/output or word processor files are not acceptable.

Failure to name file `homework5.rmd` or include author name may result in 5 points taken off.

### Question 1 ###

**24 points**

Import the HAART dataset (`haart.csv`) from the GitHub repository into R, and perform the following manipulations: (4 points each)

1. Convert date columns into a usable (for analysis) format.  Use the `table` command to display the counts of the year from `init.date`.

```{r}
HAART = read.csv('haart.csv')
#HAARTF = format(HAART)
#sub(HAART)
#init = HAARTF ['init.date']
#initv = as.vector(init)
#initl = as.list(init)
#as.Date(forini, "%m/%d/%y")
#forini = format(initv, "%m-%d-%Y")
dates = as.Date(HAART[,9], "%m/%d/%y" )
years = format(dates, "%Y")
count1 = table(years)

```

2. Create an indicator variable (one which takes the values 0 or 1 only) to represent death within 1 year of the initial visit.  How many observations died in year 1?

```{r}

#cat.names(HAART)
#CatNames(1:1000)

deads = subset(HAART, death==1)
iniddates = as.Date(deads[,9], "%m/%d/%y" )
ddates = as.Date(deads[,12], "%m/%d/%y" )
lifetime = ddates - iniddates
indicator = as.numeric(lifetime < 365)
indicator
diedearly = table(indicator)
answer = diedearly[names(diedearly) == 1]
answer

```

3. Use the `init.date`, `last.visit` and `death.date` columns to calculate a followup time (in days), which is the difference between the first and either the last visit or a death event (whichever comes first). If these times are longer than 1 year, censor them (this means if the value is above 365, set followup to 365).  Print the quantile for this new variable.

```{r}
iniddates3 = as.Date(HAART[,9], "%m/%d/%y" )
ddates3 = as.Date(HAART[,12], "%m/%d/%y" )
lastdates2 = as.Date(HAART[,10], "%m/%d/%y")
followup <- lastdates2 -iniddates2
followup2 <- ddates2 - iniddates2

#followupn = as.numeric(followup)
quantile(followup, na.rm = T)
#merge(followup, followup2)
#if =NA
# else
   
#if (followup > 365, length=1000){
#followup=365
#}
```

4. Create another indicator variable representing loss to followup; this means the observation is not known to be dead but does not have any followup visits after the first year.  How many records are lost-to-followup?

```{r}
#if last visit is NA, person is dead
undead = subset(HAART, death==0)
iniddates4 = as.Date(undead[,9], "%m/%d/%y" )
lastdates4 = as.Date(undead[,10], "%m/%d/%y" )
followtime = lastdates4 - iniddates4
indicator4 = as.numeric(followtime > 365)
indicator4
followuploss = table(indicator4)
answer4 = followuploss[names(followuploss) == 1]
answer4

```

5. Recall our work in class, which separated the `init.reg` field into a set of indicator variables, one for each unique drug. Create these fields and append them to the database as new columns.  Which drug regimen are found over 100 times?

```{r}
haartchar <- as.character(HAART[,8])
regimen <- strsplit(haartchar, ",")
all.reg <- unique(unlist(regimen))
ind.reg <- t(sapply(regimen, FUN=function(i) as.numeric(all.reg %in% i)))
colnames(ind.reg) <- all.reg

colSums(ind.reg)
haart5 <- merge(HAART, ind.reg)
```

3CT, AZT, EFV, NVP, D4T are above 100.

6. The dataset `haart2.csv` contains a few additional observations for the same study. Import these and append them to your master dataset (if you were smart about how you coded the previous steps, cleaning the additional observations should be easy!).  Show the first five records and the last five records of the complete (and clean) data set.

```{r}
HAART2 = read.csv('haart2.csv')
HAART3 = rbind(HAART, HAART2)
haartchar3 <- as.character(HAART3[,8])
regimen3 <- strsplit(haartchar3, ",")
all.reg3 <- unique(unlist(regimen3))
ind.reg3 <- t(sapply(regimen3, FUN=function(i) as.numeric(all.reg3 %in% i)))
colnames(ind.reg3) <- all.reg3


haart6 <- merge(HAART3, ind.reg3)
head(haart6, 5)
tail(haart6, 5)

```


### Question 2 ###

**10 points**

Obtain the code for using Newton's Method to estimate logistic regression parameters (`logistic.r`) and modify it to predict `death` from `weight`, `hemoglobin` and `cd4baseline` in the HAART dataset. Use complete cases only. Report the estimates for each parameter, including the intercept.

Note: The original script `logistic_debug.r` is in the exercises folder.  It needs modification, specifically, the logistic function should be defined:

```{r}
data <- read.table("~/Bios6301/datasets/logistic.csv", sep=",", head=T)

#2haart <- HAART[,4,5,6,10]

# Logistic function
logistic <- function(x) 1 / (1 + exp(-x))

x <- data[1:2]
y <- data[3]


estimate_logistic <- function(x, y, MAX_ITER=10) {

    n <- dim(x)[1]
    k <- dim(x)[2]

    x <- as.matrix(cbind(rep(1, n), x))
    y <- as.matrix(y)

    # Initialize fitting parameters
    theta <- rep(0, k+1)

    J <- rep(0, MAX_ITER)

    for (i in 1:MAX_ITER) {

        # Calculate linear predictor
        z <- x %*% theta
        # Apply logit function
        h <- logistic(z)

        # Calculate gradient
        grad <- t((1/n)*x) %*% as.matrix(h - y)
        # Calculate Hessian
        H <- t((1/n)*x) %*% diag(array(h)) %*% diag(array(1-h)) %*% x

        # Calculate log likelihood
        J[i] <- (1/n) %*% sum(-y * log(h) - (1-y) * log(1-h))

        # Newton's method
        theta <- theta - solve(H) %*% grad
    }

    return(theta)
}

estimate_logistic(x, y)
# Compare with R's built-in linear regression
g <- glm(disease ~ test1 + test2, data=data, family=binomial(logit))
print(g$coefficients)
HAARTcomp <-
logistic <- function(x) 1 / (1 + exp(-x))
```

### Question 3 ###

**14 points**

Import the `addr.txt` file from the GitHub repository.  This file contains a listing of names and addresses (thanks google).  Parse each line to create a data.frame with the following columns: lastname, firstname, streetno, streetname, city, state, zip.  Keep middle 
initials or abbreviated names in the firstname column.  Print out the entire data.frame.

```{r}
address = readLines('addr.txt')

#read.table('addr.txt', header = FALSE, sep = " ")
scan('addr.txt', what = character())
scan('addr.txt', sep = "", col.names =  'firstname', 'streetno', 'streetname', 'city', 'state', 'zip' )
address <- (read.delim('addr.txt', header = FALSE, sep = "", col.names = 'lastname', 'firstname', 'streetno', 'streetname', 'city', 'state', 'zip', numerals = "no.loss"))

cont <- as.data.frame(address)

```


### Question 4 ###

**2 points**

The first argument to most functions that fit linear models are formulas.  The following example defines the response variable `death` and allows the model to incorporate all other variables as terms. `.` is used to mean all columns not otherwise in the formula.

```{r}
url <- "https://github.com/fonnesbeck/Bios6301/raw/master/datasets/haart.csv"
haart_df <- read.csv(url)[,c('death','weight','hemoglobin','cd4baseline')]
coef(summary(glm(death ~ ., data=haart_df, family=binomial(logit))))
```

Now imagine running the above several times, but with a different response and data set each time.  Here's a function:

```{r}
myfun <- function(dat, response) {
  form <- as.formula(response ~ .)
  coef(summary(glm(form, data=dat, family=binomial(logit))))
}
```

Unfortunately, it doesn't work. `tryCatch` is "catching" the error so that this file can be knit to PDF.

```{r}
tryCatch(myfun(haart_df, death), error = function(e) e)
```

What do you think is going on?  Consider using `debug` to trace the problem.

**5 bonus points**

Create a working function.
